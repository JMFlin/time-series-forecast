stopCluster(cl)
# Load libraries
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
"h2o", # Awesome ML Library
"timetk", # Toolkit for working with time series in R
"futile.logger", # Adds logging
"tidyquant", # Loads tidyverse, financial pkgs, used to get data
"janitor", # COlumn name handling
"glue", # A better paste function
"styler", # Style r code
"sweep", # Broom-style tidiers for the forecast package
"forecast", # Forecasting models and predictions package
"caret", # Awesome ML Library
"doParallel",
"recipes"
)
setwd("C:/Users/janne/Documents/time-series-forecast")
stopCluster(cl)
file.sources <- list.files("utils",
pattern = "*.R$", full.names = TRUE,
ignore.case = TRUE
)
invisible(sapply(file.sources, source, .GlobalEnv))
h2o.init() # Fire up h2o
h2o.no_progress() # Turn off output of progress bars
n <- 3
unit.of.measurement <- "unit"
factor.limit <- 1
regression.control  <- trainControl(method = "cv",
number = 3
)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
Main <- function() {
flog.info("Loading data")
forecast.data <- LoadData(unit.of.measurement)
data.frequency <- forecast.data %>%
tk_index() %>%
tk_get_timeseries_summary() %>%
select(scale)
flog.info("Plotting time series")
InitialPlot(forecast.data, data.frequency)
flog.info("Cleaning target data")
forecast.data.cleaned <- CleanTarget(forecast.data, data.frequency)
max.lag <<- round(nrow(forecast.data.cleaned) * 0.4)
optimal.lag.setting <<- forecast.data.cleaned %>%
TidyAcf(unit, lags = 1:max.lag) %>%
filter(acf == max(acf)) %>%
pull(lag)
flog.info("Plotting ACF")
AcfPlot(forecast.data.cleaned)
flog.info("Creating timetk features")
forecast.data.features <- CreateTimeTkFeatures(forecast.data.cleaned)
flog.info("Cleaning features data")
forecast.data.cleaned <- CleanFeatures(forecast.data.features)
flog.info("Starting multivariate modeling with h2o")
MultivariateSeriesH2O(forecast.data.cleaned)
flog.info("Starting multivariate modeling with lm")
MultivariateSeriesLM(forecast.data.cleaned)
flog.info("Starting univariate modeling with arima, ets and tbats")
UnivariateSeries(forecast.data.cleaned)
}
Main()
flog.info("Loading data")
forecast.data <- LoadData(unit.of.measurement)
data.frequency <- forecast.data %>%
tk_index() %>%
tk_get_timeseries_summary() %>%
select(scale)
flog.info("Plotting time series")
InitialPlot(forecast.data, data.frequency)
flog.info("Cleaning target data")
forecast.data.cleaned <- CleanTarget(forecast.data, data.frequency)
max.lag <<- round(nrow(forecast.data.cleaned) * 0.4)
optimal.lag.setting <<- forecast.data.cleaned %>%
TidyAcf(unit, lags = 1:max.lag) %>%
filter(acf == max(acf)) %>%
pull(lag)
flog.info("Plotting ACF")
AcfPlot(forecast.data.cleaned)
flog.info("Creating timetk features")
forecast.data.features <- CreateTimeTkFeatures(forecast.data.cleaned)
flog.info("Cleaning features data")
forecast.data.cleaned <- CleanFeatures(forecast.data.features)
flog.info("Cleaning augmented data")
forecast.data.cleaned <- forecast.data.features %>%
clean_names() %>%
remove_empty(c("cols")) %>%
#select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor())
flog.info("Finding near zero variane features")
zero.variance.columns <- nearZeroVar(forecast.data.features, names = TRUE)
zero.variance.columns
flog.info("Removing near zero variane features")
forecast.data.removed <- forecast.data.features %>%
dplyr::select(-one_of(zero.variance.columns))
#Numeric Factor Data
unique.numeric.values.tbl <- forecast.data.removed %>%
select_if(is.numeric) %>%
map_df(~ unique(.) %>% length()) %>%
gather() %>%
arrange(value) %>%
mutate(key = as_factor(key))
num.2.factor.names <- unique.numeric.values.tbl %>%
filter(value <= factor.limit) %>%
arrange(desc(value)) %>%
pull(key) %>%
as.character()
unique.numeric.values.tbl
num.2.factor.names
num.2.factor.names <- unique.numeric.values.tbl %>%
filter(value <= factor.limit) %>%
arrange(desc(value)) %>%
pull(key) %>%
as.character()
#Missing Data
missing.tbl <- forecast.data.removed %>%
summarize_all(.funs = ~ sum(is.na(.)) / length(.)) %>%
gather() %>%
arrange(desc(value)) %>%
filter(value > 0)
#Impute Data
rec.obj <<- recipe(~ ., data = forecast.data.removed) %>%
#step_string2factor(string.2.factor.names) %>%
step_num2factor(num.2.factor.names) %>%
#step_meanimpute(all_numeric()) %>%
step_modeimpute(all_nominal()) %>%
prep(stringsAsFactors = FALSE)
num.2.factor.names
num.2.factor.names %>% is_empty()
CleanFeatures <- function(forecast.data.features) {
flog.info("Cleaning augmented data")
forecast.data.cleaned <- forecast.data.features %>%
clean_names() %>%
remove_empty(c("cols")) %>%
#select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor())
flog.info("Finding near zero variane features")
zero.variance.columns <- nearZeroVar(forecast.data.features, names = TRUE)
flog.info("Removing near zero variane features")
forecast.data.removed <- forecast.data.features %>%
dplyr::select(-one_of(zero.variance.columns))
#Numeric Factor Data
unique.numeric.values.tbl <- forecast.data.removed %>%
select_if(is.numeric) %>%
map_df(~ unique(.) %>% length()) %>%
gather() %>%
arrange(value) %>%
mutate(key = as_factor(key))
num.2.factor.names <- unique.numeric.values.tbl %>%
filter(value <= factor.limit) %>%
arrange(desc(value)) %>%
pull(key) %>%
as.character()
#Missing Data
missing.tbl <- forecast.data.removed %>%
summarize_all(.funs = ~ sum(is.na(.)) / length(.)) %>%
gather() %>%
arrange(desc(value)) %>%
filter(value > 0)
#Impute Data
if (num.2.factor.names %>% is_empty()) {
rec.obj <<- recipe(~ ., data = forecast.data.removed) %>%
step_modeimpute(all_nominal()) %>%
prep(stringsAsFactors = FALSE)
} else {
rec.obj <<- recipe(~ ., data = forecast.data.removed) %>%
#step_string2factor(string.2.factor.names) %>%
step_num2factor(num.2.factor.names) %>%
#step_meanimpute(all_numeric()) %>%
step_modeimpute(all_nominal()) %>%
prep(stringsAsFactors = FALSE)
}
forecast.data.cleaned <- bake(rec.obj, forecast.data.removed) %>%
clean_names() %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor())
return(forecast.data.cleaned)
}
file.sources <- list.files("utils",
pattern = "*.R$", full.names = TRUE,
ignore.case = TRUE
)
invisible(sapply(file.sources, source, .GlobalEnv))
n <- 3
unit.of.measurement <- "unit"
factor.limit <- 1
regression.control  <- trainControl(method = "cv",
number = 3
)
flog.info("Loading data")
forecast.data <- LoadData(unit.of.measurement)
data.frequency <- forecast.data %>%
tk_index() %>%
tk_get_timeseries_summary() %>%
select(scale)
flog.info("Plotting time series")
InitialPlot(forecast.data, data.frequency)
flog.info("Cleaning target data")
forecast.data.cleaned <- CleanTarget(forecast.data, data.frequency)
max.lag <<- round(nrow(forecast.data.cleaned) * 0.4)
optimal.lag.setting <<- forecast.data.cleaned %>%
TidyAcf(unit, lags = 1:max.lag) %>%
filter(acf == max(acf)) %>%
pull(lag)
flog.info("Plotting ACF")
AcfPlot(forecast.data.cleaned)
flog.info("Creating timetk features")
forecast.data.features <- CreateTimeTkFeatures(forecast.data.cleaned)
flog.info("Cleaning features data")
forecast.data.cleaned <- CleanFeatures(forecast.data.features)
flog.info("Starting multivariate modeling with h2o")
MultivariateSeriesH2O(forecast.data.cleaned)
n <- 3
unit.of.measurement <- "unit"
factor.limit <- 3
regression.control  <- trainControl(method = "cv",
number = 3
)
flog.info("Loading data")
forecast.data <- LoadData(unit.of.measurement)
data.frequency <- forecast.data %>%
tk_index() %>%
tk_get_timeseries_summary() %>%
select(scale)
flog.info("Plotting time series")
InitialPlot(forecast.data, data.frequency)
flog.info("Cleaning target data")
forecast.data.cleaned <- CleanTarget(forecast.data, data.frequency)
max.lag <<- round(nrow(forecast.data.cleaned) * 0.4)
optimal.lag.setting <<- forecast.data.cleaned %>%
TidyAcf(unit, lags = 1:max.lag) %>%
filter(acf == max(acf)) %>%
pull(lag)
flog.info("Plotting ACF")
AcfPlot(forecast.data.cleaned)
flog.info("Creating timetk features")
forecast.data.features <- CreateTimeTkFeatures(forecast.data.cleaned)
flog.info("Cleaning features data")
forecast.data.cleaned <- CleanFeatures(forecast.data.features)
flog.info("Starting multivariate modeling with h2o")
MultivariateSeriesH2O(forecast.data.cleaned)
rm(list())
rm(list=ls())
stopCluster(cl)
setwd("C:/Users/janne/Documents/time-series-forecast")
# Load libraries
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
"h2o", # Awesome ML Library
"timetk", # Toolkit for working with time series in R
"futile.logger", # Adds logging
"tidyquant", # Loads tidyverse, financial pkgs, used to get data
"janitor", # COlumn name handling
"glue", # A better paste function
"styler", # Style r code
"sweep", # Broom-style tidiers for the forecast package
"forecast", # Forecasting models and predictions package
"caret", # Awesome ML Library
"doParallel",
"recipes"
)
file.sources <- list.files("utils",
pattern = "*.R$", full.names = TRUE,
ignore.case = TRUE
)
invisible(sapply(file.sources, source, .GlobalEnv))
h2o.init() # Fire up h2o
h2o.no_progress() # Turn off output of progress bars
n <- 3
unit.of.measurement <- "unit"
factor.limit <- 3
regression.control  <- trainControl(method = "cv",
number = 3
)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
flog.info("Loading data")
forecast.data <- LoadData(unit.of.measurement)
data.frequency <- forecast.data %>%
tk_index() %>%
tk_get_timeseries_summary() %>%
select(scale)
flog.info("Plotting time series")
InitialPlot(forecast.data, data.frequency)
flog.info("Cleaning target data")
forecast.data.cleaned <- CleanTarget(forecast.data, data.frequency)
max.lag <<- round(nrow(forecast.data.cleaned) * 0.4)
optimal.lag.setting <<- forecast.data.cleaned %>%
TidyAcf(unit, lags = 1:max.lag) %>%
filter(acf == max(acf)) %>%
pull(lag)
flog.info("Plotting ACF")
AcfPlot(forecast.data.cleaned)
flog.info("Creating timetk features")
forecast.data.features <- CreateTimeTkFeatures(forecast.data.cleaned)
flog.info("Cleaning features data")
forecast.data.cleaned <- CleanFeatures(forecast.data.features)
flog.info("Starting multivariate modeling with h2o")
MultivariateSeriesH2O(forecast.data.cleaned)
